[1728064887] warming up the model with an empty run
[1728064888] warming up the model with an empty run
[1728064888] warming up the model with an empty run
[1728064889] warming up the model with an empty run
[1728064889] warming up the model with an empty run
[1728064893] warming up the model with an empty run
[1728064894] warming up the model with an empty run
[1728064898] warming up the model with an empty run
[1728064898] warming up the model with an empty run
[1728064899] warming up the model with an empty run
[1728064899] warming up the model with an empty run
[1728064903] warming up the model with an empty run
[1728064903] warming up the model with an empty run
[1728064904] warming up the model with an empty run
[1728064925] warming up the model with an empty run
[1728064925] Log start
[1728064925] llama_generate_text: build = 3029 (b864b50c)
[1728064925] llama_generate_text: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu
[1728064925] llama_generate_text: seed  = 1728064925
[1728064925] llama_generate_text: llama backend init
[1728064925] llama_generate_text: load the model and apply lora adapter, if any
[1728064925] llama_generate_text: error: unable to load model
