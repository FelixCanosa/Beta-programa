[1728409631] warming up the model with an empty run
[1728409631] warming up the model with an empty run
[1728409632] warming up the model with an empty run
[1728409632] warming up the model with an empty run
[1728409632] warming up the model with an empty run
[1728409632] warming up the model with an empty run
[1728409632] warming up the model with an empty run
[1728409633] warming up the model with an empty run
[1728409633] warming up the model with an empty run
[1728409633] warming up the model with an empty run
[1728409633] warming up the model with an empty run
[1728409633] warming up the model with an empty run
[1728409633] warming up the model with an empty run
[1728409633] warming up the model with an empty run
[1728409638] warming up the model with an empty run
[1728409638] Log start
[1728409638] llama_generate_text: build = 3029 (b864b50c)
[1728409638] llama_generate_text: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu
[1728409638] llama_generate_text: seed  = 1728409638
[1728409638] llama_generate_text: llama backend init
[1728409638] llama_generate_text: load the model and apply lora adapter, if any
[1728409639] llama_generate_text: error: unable to load model
